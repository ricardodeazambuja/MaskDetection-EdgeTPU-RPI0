{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802ff5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Did you install the TFLite Runtime? \\\n",
    "    https://github.com/ricardodeazambuja/libedgetpu-rpi0/releases/tag/rpi0_tflite_edgetpu\")\n",
    "\n",
    "\n",
    "EDGETPU_SHARED_LIB = 'libedgetpu.so.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49e89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    if \"edgetpu\" in model_file:\n",
    "        print(\"Using Edge TPU...\")\n",
    "        #\n",
    "        # EdgeTPU Accelerator\n",
    "        #\n",
    "        device = [] # I have only one USB accelerator...\n",
    "        tflite_interpreter = tflite.Interpreter(model_path=model_file, \n",
    "                                         experimental_delegates=[tflite.load_delegate(EDGETPU_SHARED_LIB,{'device': device[0]} if device else {})])\n",
    "    else:\n",
    "        print(\"Using CPU...\")\n",
    "        tflite_interpreter = tflite.Interpreter(model_path=model_file)\n",
    "        \n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    input_details = tflite_interpreter.get_input_details()\n",
    "    output_details = tflite_interpreter.get_output_details()\n",
    "    \n",
    "    return tflite_interpreter, input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9127fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference_for_single_image_tflite:\n",
    "    def __init__(self, path_to_model):\n",
    "        tflite_interpreter, input_details, output_details = load_model(path_to_model)\n",
    "        self.interpreter = tflite_interpreter\n",
    "\n",
    "        self.input_details = input_details\n",
    "        self.output_details = output_details\n",
    "        self.width = self.input_details[0]['shape'][2]\n",
    "        self.height = self.input_details[0]['shape'][1]\n",
    "\n",
    "    def __call__(self, image_np_expanded):\n",
    "        self.interpreter.set_tensor(self.input_details[0]['index'], image_np_expanded)\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        return [self.interpreter.get_tensor(self.output_details[out_i]['index'])[0] for out_i in range(len(self.output_details))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00fabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "            \n",
    "def process_bboxes(image, boxes, classes, scores, threshold=0.5, \n",
    "                   labels={1:'mask', 2: 'no_mask', 3:'poor_mask'},\n",
    "                   crop=False):\n",
    "    colors = ((128, 255, 102), (102, 255, 255), (232, 123, 212))\n",
    "    colors = dict(zip(labels.keys(),colors))\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    if not crop:\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        # Visualization of the results of a detection.\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] > threshold:\n",
    "                ymin = int(max(1, (boxes[i][0] * image_height)))\n",
    "                xmin = int(max(1, (boxes[i][1] * image_width)))\n",
    "                ymax = int(min(image_height, (boxes[i][2] * image_height)))\n",
    "                xmax = int(min(image_width, (boxes[i][3] * image_width)))\n",
    "                draw.rectangle((xmin, ymin, xmax, ymax), width=3, outline=colors[int(classes[i])])\n",
    "                text = f'{labels[int(classes[i])]} {scores[i]*100:1.2f}%'\n",
    "                draw.text((xmin+3, ymin-10), text, fill=colors[int(classes[i])], width=2)\n",
    "        return image\n",
    "    else:\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] >= threshold:\n",
    "                box = boxes[i]\n",
    "                ymin = int(max(1, (boxes[i][0] * image_height)))\n",
    "                xmin = int(max(1, (boxes[i][1] * image_width)))\n",
    "                ymax = int(min(image_height, (boxes[i][2] * image_height)))\n",
    "                xmax = int(min(image_width, (boxes[i][3] * image_width)))\n",
    "                return image.crop((xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b851f",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d19cfd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘mask_example1.jpg’ already there; not retrieving.\n",
      "File ‘mask_example2.jpg’ already there; not retrieving.\n",
      "File ‘mask_example3.jpg’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget --no-clobber \"https://images.canadagoose.com/image/upload/w_1333,c_scale,f_auto,q_auto:best/v1601577550/product-image/5558U_1073.jpg\" -O mask_example1.jpg\n",
    "!wget --no-clobber  \"https://i.cbc.ca/1.5901311.1612993040!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/face-recognition-test.jpg\" -O mask_example2.jpg\n",
    "!wget --no-clobber  \"https://media.npr.org/assets/img/2021/01/29/_dsf1400_custom-01c8b25d39b298816ef6996981e39e40477fe7c6.jpg\" -O mask_example3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77f162d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filename = \"mask_example2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfe17eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_TFLITE = \"ssdlite_mobiledet_mask.tflite\"\n",
    "PATH_TO_TFLITE = \"ssdlite_mobiledet_mask_edgetpu.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e5955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Edge TPU...\n"
     ]
    }
   ],
   "source": [
    "run_inference_for_single_image_tflite_ssd = inference_for_single_image_tflite(PATH_TO_TFLITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f055ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = Image.open(img_filename)\n",
    "image = image.convert('RGB')\n",
    "image_width, image_height = image.size\n",
    "\n",
    "# tflite will not have the image resizing in the model\n",
    "input_width = run_inference_for_single_image_tflite_ssd.width\n",
    "input_height = run_inference_for_single_image_tflite_ssd.height\n",
    "\n",
    "resized_image = image.resize((input_width, input_height))\n",
    "np_image = np.asarray(resized_image)\n",
    "\n",
    "image_np_expanded = np.expand_dims(np_image, axis=0)\n",
    "\n",
    "# Actual detection.\n",
    "boxes, classes, scores, _ = run_inference_for_single_image_tflite_ssd(image_np_expanded)\n",
    "\n",
    "classes = [i+1 for i in classes] # class indices here start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed890fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6beed231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80078125, 0.72265625, 0.27734375, 0.19921875, 0.11328125,\n",
       "       0.1015625 , 0.09375   , 0.09375   , 0.08203125, 0.08203125],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38eced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_bboxes(resized_image.copy(), boxes, classes, scores, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "922d0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.5588072470000043\n",
      "FPS: 17.895258255303055\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_loops = 10\n",
    "init_time = time.monotonic()\n",
    "for i in range(total_loops):\n",
    "    # Actual detection.\n",
    "    boxes, classes, scores, _ = run_inference_for_single_image_tflite_ssd(image_np_expanded)\n",
    "    \n",
    "final_time = time.monotonic()\n",
    "print(f\"Total time: {final_time-init_time}\")\n",
    "print(f\"FPS: {1/((final_time-init_time)/total_loops)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
